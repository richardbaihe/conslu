{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(model, dev_data, config):\n",
    "    model.eval()\n",
    "    dev_data_1, dev_data_2 = dev_data\n",
    "    index2slot = {v: k for k, v in model.slot_vocab.items()}\n",
    "    preds = []\n",
    "    labels = []\n",
    "    hits = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader(dev_data_1, 32, False)):\n",
    "            h, c, slot, intent = pad_to_batch(batch, model.vocab, model.slot_vocab)\n",
    "            h = [hh.to(device) for hh in h]\n",
    "            c = c.to(device)\n",
    "            slot = slot.to(device)\n",
    "            intent = intent.to(device)\n",
    "            slot_p, intent_p = model(h, c)\n",
    "\n",
    "            preds.extend([index2slot[i] for i in slot_p.max(1)[1].tolist()])\n",
    "            labels.extend([index2slot[i] for i in slot.view(-1).tolist()])\n",
    "            hits += torch.eq(intent_p.max(1)[1], intent.view(-1)).sum().item()\n",
    "        if config.slm_weight>0:\n",
    "            slm_label_all = []\n",
    "            slm_pred_all = []\n",
    "            for i, batch in enumerate(data_loader(dev_data_2, 32, False)):\n",
    "                slm_h, slm_candi, slm_label = pad_to_batch_slm(batch, model.vocab)\n",
    "                slm_h = [hh.to(device) for hh in slm_h]\n",
    "                slm_candi = [hh.to(device) for hh in slm_candi]\n",
    "                slm_label = slm_label.to(device)\n",
    "                slm_p = model(slm_h, slm_candi, slm=True).view(-1, 2)\n",
    "                slm_label_all.extend(slm_label.view(-1).tolist())\n",
    "                slm_pred_all.extend(slm_p.max(1)[1].tolist())\n",
    "\n",
    "            slm_acc = accuracy_score(slm_label_all, slm_pred_all)\n",
    "            slm_recall = recall_score(slm_label_all, slm_pred_all)\n",
    "            print('slm accuracy:\\t%.5f' % slm_acc)\n",
    "            print('slm recall:\\t%.5f' % slm_recall)\n",
    "    intent_acc = hits / len(dev_data_1)\n",
    "    print('intent accuracy:\\t%.5f' % intent_acc)\n",
    "\n",
    "    sorted_labels = sorted(\n",
    "        list(set(labels) - {'O', '<pad>'}),\n",
    "        key=lambda name: (name[1:], name[0])\n",
    "    )\n",
    "\n",
    "    # this is because sklearn_crfsuite.metrics function flatten inputs\n",
    "    preds = [[y] for y in preds]\n",
    "    labels = [[y] for y in labels]\n",
    "\n",
    "    print(metrics.flat_classification_report(\n",
    "        labels, preds, labels=sorted_labels, digits=3\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_utils import *\n",
    "from model import SDEN\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('weight/model.pkl',map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = checkpoint['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SDEN(len(checkpoint['vocab']),config.embed_size,config.hidden_size,\n",
    "             len(checkpoint['slot_vocab']),len(checkpoint['intent_vocab']))\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SDEN(\n",
       "  (embed): Embedding(1179, 100, padding_idx=0)\n",
       "  (bigru_m): GRU(100, 64, batch_first=True, bidirectional=True)\n",
       "  (bigru_c): GRU(100, 64, batch_first=True, bidirectional=True)\n",
       "  (context_encoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (session_encoder): GRU(128, 128, batch_first=True, bidirectional=True)\n",
       "  (decoder_1): GRU(100, 128, batch_first=True, bidirectional=True)\n",
       "  (decoder_2): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "  (intent_linear): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (slot_linear): Linear(in_features=256, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.3)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_test_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2intent = {v:k for k,v in checkpoint['intent_vocab'].items()}\n",
    "index2slot = {v:k for k,v in checkpoint['slot_vocab'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = random.sample(data,2)\n",
    "index = random.choice([i for i in range(len(test[0]['dialogue'])) if i%2==0])\n",
    "test = test[0]['dialogue'][:index] + test[1]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'date', 'and', 'time', 'of', 'my', 'next', 'meeting', 'and', 'who', 'will', 'be', 'attending', 'it', '?']\n",
      "intent :  schedule\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-event', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "['Please', 'give', 'me', 'the', 'address', 'and', 'directions', 'via', 'a', 'route', 'with', 'no', 'traffic', 'to', 'the', 'nearest', 'pizza', 'restaurant', '.']\n",
      "intent :  navigate\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-traffic_info', 'O', 'O', 'B-distance', 'B-poi_type', 'I-poi_type', 'O']\n",
      "\n",
      "['Yes', ',', 'let', \"'s\", 'go', ',', 'thank', 'you', '!']\n",
      "intent :  thanks\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history=[[\"<null>\"]]\n",
    "for d in test:\n",
    "    utter = d['data']['utterance']\n",
    "    token = nltk.word_tokenize(utter)\n",
    "    c = prepare_sequence(token,checkpoint['vocab']).unsqueeze(0)\n",
    "    h = pad_to_history(history,checkpoint['vocab'])\n",
    "    with torch.no_grad():\n",
    "        s,i = model(h,c)\n",
    "    slot_p = s.max(1)[1]\n",
    "    intent_p = i.max(1)[1]\n",
    "    if d['turn']=='driver':\n",
    "        print(token)\n",
    "        print('intent : ',index2intent[intent_p.item()])\n",
    "        print('slot : ',[index2slot[s] for s in slot_p.data.tolist()])\n",
    "        print(\"\")\n",
    "    history.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
